# BBF config: https://github.com/google-research/google-research/blob/a3e7b75d49edc68c36487b2188fa834e02c12986/bigger_better_faster/bbf/configs/BBF.gin

game: "assault" # 'assault' | 'road_runner' | 'amidar' | 'breakout'
n_actions: 7 # assault: 7, road_runner: 18, breakout: 4, amidar: 10
batch_size: 32
subseq_len: 10
target_ema_tau: 0.005 # how much to interpolate weights for the EMA of the target network
epsilon: 0.05 
epsilon_decay_period: 8001
epsilon_train: 0.1
initial_collect_steps: 2000
learning_rate: 0.0001
weight_decay: 0.02
frameskip: 4
stack_frames: 4
renormalize: True
double_DQN: True
distributional_DQN: True
dueling_DQN: True
target_update_frequency: 1
target_action_selection: True # whether to use the target network for action selection during data collection
audio: False
prioritized: True

hidden_dim: 2048 # size of the projection / prediction layers
num_atoms: 51
vmax: 10
spr_loss_weight: 5 # relative to RL loss

encoder_network: "ImpalaWide" # 'DQN' (3-layer CNN) or 'ImpalaWide' (15-layer ResNet)

reset_target: True
spr_prediction_depth: 5
start_gamma: 0.97
end_gamma: 0.997
start_update_horizon: 10
end_update_horizon: 3
replay_ratio: 2
perturb_factor: 0.5
clip_reward: True
process_inputs: True
shrink_factor: 0.5

evaluation_epsilon: 0.001

replay_capacity: 200000
reset_every: 40_000
min_episodes: 3
num_env_steps: 100_000 # Atari 100k

## Pre-processing
data_augmentation: True
scale_type: 'linear' # 'linear' or 'crop' or 'none'

summaries_dir: '../runs/summaries/'
model_dir: '../runs/models/'
video_dir: '../videos/'
eval_frequency: 5000
train_log_frequency: 4
print_frequency: 100
evaluation_episodes: 5